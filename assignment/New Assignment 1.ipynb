{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ed755f88fd1d8449b34047eca65990d0",
     "grade": false,
     "grade_id": "cell-e9469d5507bcd8ea",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Assignment 01: Supervised learning, Linear models, and Loss functions\n",
    "\n",
    "\n",
    "\n",
    "## Data set \n",
    "\n",
    "In this assignment, you'll be working with some data on possums.  It's a relatively small data set, but it's a good size to get you started with ordinary least squares (OLS) and least absolute deviation (LAD), and to gain experience with supervised learning in general.  You're going to write your own methods to fit both OLS and LAD models, and then at the end compare them to the models produced by the `statsmodels` package.\n",
    "\n",
    "For this assignment, we will examine some data representing possums in Australia and New Guinea.\n",
    "The code below loads in a pandas data frame with 46 observations on the following 6 variables:\n",
    "\n",
    "sex: Sex, either m (male) or f (female).  \n",
    "age: Age in years.  \n",
    "headL: Head length, in mm.  \n",
    "skullW: Skull width, in mm.  \n",
    "totalL: Total length, in cm.  \n",
    "tailL: Tail length, in cm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "934f3d0215af307e91b80c6f69f4ad1a",
     "grade": false,
     "grade_id": "cell-1be2a58cd5936840",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Task 1: OLS estimation and plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "99532d132694eec53bf6393c4c9f98d1",
     "grade": false,
     "grade_id": "cell-03c1e147d3ce4866",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#It's dangerous to go alone.  Take these!\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss \n",
    "import scipy.optimize as so\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "#Read in the data you will need for this assignment\n",
    "possum_data=pd.read_csv('possum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8f0f976f9d8ca247c622e11b0b09a3ec",
     "grade": false,
     "grade_id": "cell-79ccc5f0096af1b5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 1:\n",
    "\n",
    "Investigate the relationship between the possum's age and it's tail length by plotting a scatter plot of the `age` and `tailL` columns. Label your plot and your axes. You might want to add an `alpha` in case some data are overlapping.  Perform any other exploratory analysis you think might be useful (optional.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a892afff62c39e657a195d50f2e24da1",
     "grade": true,
     "grade_id": "cell-edd979fb2a7259e8",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEaCAYAAAD3+OukAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxdZZ3n8c+vqhKSFAlbBZIYwxYEEUloI4J08yIsdmgZFGZ4hu5mk5HYM0jTLd02Lg0oLa0Ogo7twqKC4PZTw6i0E+lm17Ztg0tEgTZAICSQBQJZIVTdM388TyU3N7Xd5NY5p+p8369Xve69p87yu8855/7O8zxnsSzLEBGRamorOgARESmOkoCISIUpCYiIVJiSgIhIhSkJiIhUmJKAiEiFKQn0wczuM7ObWzCfE8wsM7PprYirieUOGr+ZXWVmS1qwrKVm9uFdnc9o1apyrhIzu8DMuvOY91D20TKuw1b9RsEoSgJmdktamZmZ9ZjZM2b2VTN7TU7L7zazCxoG/xswFViRRwxNuhY4puggevVTfiOGmU1P294JRcdSBWa2xMyu2olJvwXk8pvQCmZ2jpkN68VcoyYJJA8Sf3RnAH8GHAV8u6hgsizbkmXZc1mW1YqKoT9Zlm3IsmxN0XGI5CnLss1Zlq0sOo4yGW1JoPdHd3mWZQ8ANwLHmtmk+pHM7BIze9TMXjaz35vZh8yso7+Zmtkpqfr1gpm9ZGb3m9nRdf9fCrQDX+mtjaThO1Q1zewYM3vAzDab2Voz+7qZ7Vv3/6vSUc47UowbzexeMzu4bpxJZvYVM3vOzF4xs2Vmdl0fcf99GueFVFPqbFxOH8v9MzN7IpXNv5rZgUMo9/FmdrOZrTOzNWb2CTPbum2ZWUea/5Npvr81s/cMofyWmdm768a7Nf1/Zt2wp8zsf9V9PtvMfpWWs9TMrqv/3mmcAdd/mu6jZvaZVHYrzexaM2sfoAyWpdd7U4xLG5bZ7/pM/3+Tmd1lZhvMbLWZLTCz/Qcq9LSufpa2yTVm9s9m9rqGcY4ys39P3/U/zey/WUMTnpntnr7rcjPbZGa/NLMzB1n2gSnGFWma35jZuQ3j3Je2i4G2QzOzq81sVfru3wT2GmTZ9wEHA1fattr/AWleN5nZ4xb3ryfM7Boz261u2pY0NVn8TfhJWs5yi/vjPnX/vyXtP/PTNrrOzL5nZpMb5vNXFlstNpnZj8zs3PR9plusVd6Wxuv9nrc0TN9v2Q5ZlmWj4g+4BfjXus/TgPuBbqCzbvhVwFPAGcCBwJ8ATwNX141zH3Bz3eczgLOA1wFvAG4GXgD2Sf+fnJZzKTAFmJKGnwBkwPT0eQqwDvg68EbgD4HFwIMN8W0EFgJvAmYBvwTurxvn/wC/Bt5CrPW8FbioIf4XgeuBw4B56fNHGpazpI/l/hh4c/r7WVqODVDuS9N3+ihwKHBums/7GtbNYuBtqcz/e4rnfwxSfl8FvlE3n6eBVcB70ueDU/kelj5fAKxNMRwEHJ+We1uT639pms/lwCEp3m7gXQOUw1EpljPTd5jcxPo8HNgAfCStrzcSa7D/CYwbYJnvAk5L5XAU8H3g98DY9P8JwLPAD4Ajic1//wZsAj6cxjHg3rTN/GEqt/nAFuCkAZb9RuDiNN+DgUtSGc1tcju8NJXP+cT96/1pnO4Blr038CSxSXNK+msnHtT+A3G/OAA4PX3/+uVdUD9vGvbRfpZ3FdvvKyemMrwkbR9vTmX4AGlfIW7zLwHfAI4g7qNPAbfWzedMtm33h6TYVvTGA4xNZZzVfc89hlq2Q/7tzPvHerj+UqF3E3emTangMuDaunEmpP/Na5j2PODFho335gGW1Ub8kfjzumHdwAUN4223gQFXA8+QdtI0bFYa5/i6Da6b9COShp0N1Eg/CMD3gFsGiO8+YHHDsC8CPx1gw74qxTGzbtjr0rCTB1jWUuqSWBp2DfBMen9giv2whnGuAH41SPldAKxM7w9J6+7vAU/DLgJWNMTyFw3zOD59h72aWP9Lge83jLOQuoTURzlMT8s5oWH4UNbnLcA3G6bbLcX6zib2gb1TDMfVlc8G0g9HGnZYGqc3CZwAvFw/Thr+ZeD/NrkPfg+4qcnt8BngYw3jfIcBkkAaZwlw1RBi+mvg9w3b1K4mgfuAjzeMMyPNZ3bdOl0N7FY3zuXAs3Wff0LdAUoa9nG2/804B8j6iGnQsh3qX79NICPUz4hHFOOAAJxC/NHo9QZgPPBd276zpR0YZ2aTsyxb3ThTi00iHwWOBfYlJoEJwIDV9T68Afj3LMu29A7IsuzXZvZS+t8DafCKhjiWE4/Y9iUetX4+fYc5wN3EH6gfZdv3PfyqYdnLiUfiA1mdZdnWJqIsy/7TzNYQj1T/dYDpftrw+SfAByw2w81JsS8ys/pxOoCeQeK5G9jXzI4AjiPWUhYCf2lxZicC9wCkavb+wHVmdm3dPHoX2tuENNT131f5DaVprC+Drc83AzPNbEPDdOOIya9PZjYbuBKYDXSx7bvuT1wHhwOPZFn2Uu80WZY9amYv1s3mzcQjzuUN62cssVbR37InEBP5fyH2w40lJq57G0btdztM28driLWTej8G3tnfsgdiZhcB7ybWBDqJ21mrm73fDBxjZu/t43+HsO07P5Jl2St1/1sO7Ff3+XBiq0C9xn1pIDuzj+9gtCWBzXU/Yg+n9tHPARemYb0bw1nEqnajF/qZ753AGmLVbBmxqvxj4obfrGwIw7f08782gCzLfmRmM4A/Jh7J3A78xsxOyrKsZ4B57MzOYIOPMuA0vct8K/HItjGmfmVZtszMHgdOStPfAzxE3G6PBOYCH2xYzqXs+EME8YhzVno/lPXfqvLrb17Uza+N2Pb78T6mfb6vGaYf4buI2+GFwHPpX79l++1ywDJOy36J+MM2WNz1/jfwDuAy4FFik86ngD0GmUd9OVrdsF1mZmcR9/fLiU3B64jr+mOtmH+dNuATpPb6Bs/Vve/ruzfuT7vy3VuyjY62JNDoKuC3Zvb5LMsWEXeQl4GDsiz74VBmkDp7Dgf+JMuyH6Vh04lHcfW2EI8oB/Jb4F1mNra3NmBms4g7zm+H9pWiLMteILY3fsPMvkI8gjgc+E0z82kw2cwOzrLs8RTb64B9gEcGma7xVNNjiUe/68zsoTRsRpZldw4wj/7K7x5iEngLsWmvZmYPENtj90v/J8uylWa2DDg0y7Kb+lqAmTW9/pvQu0MOtg30ZRExqT2epXr9ELye2JfyoSzLHgEws7ey/Y/M74B3m9kevbUBMzsU2LNh2XsSm6YebiLm44GvZVn2rTTfNmLz4ZDPvMmy7CUzW06s5dWvj+OGMHlf28vxwC+zLNt6koSZHTDUeJqwCHhDfa15J/2OuK98vm5Y477U+zvRXneA11Kj7eyg7WRZ9ijxKP4f0+cNxPbqa8zsvWZ2qJm9weIZJZ/oZzZriW17F5nZ68zsWOKP7+aG8Z4E5prZNDPr6mde/wRMAm4xsyPM7A+JRxM/zrLswaF+LzP7mJmdmeI/BPhzYtvv00OdRz82Ec/QeVNqarqVmFQGagoCmG3x7J/XmdmfEY/GrwdIO8qXgZvSmQ8zzWyWmV1oZn9XN4/+yu8e4FRiU8Mv6oadDzyZZdnSunE/RGwq+nAq30PN7J1mdkOKZWfW/1CtIa6Dt5nZFDMb8AyXBtcQf9RvN7OjLZ55M9fiGTsH9TPNU8ArwCVmdrCZnQR8hu2PLL+WYvqqmR1pZm8BvkTcdnvHu4e4fheY2RlmdlBa/5ekppX+PAa8I8V7OPFMvGlNfOdenwIuTdvGIWZ2GXDyEKZ7EjjOzGaYWVdKQo8Bb7R4JtbBZnYpsfO11a4gfvfrzWx2WtY8M/uSmY1vYj6fAs5OZT3TzM4j9k/BtvXzZHo93cwmm9nuLfoOW43qJJB8Ejg57SRkWXY1sbPo3cQzX36cPi/ta+LUzn4W8QyIxcQOn08Tzzqodxnx7I8niUmjr3mtJLbZTQd+TkxQDwP/tcnv9DKxj+Ihth1Fnlrf9ruTniXuzN8ltilvBs4YwtHpZ4nt0IuIie4LpCSQzE+fP0Q8+rmb+CP+RN04/ZXfPcQjvvvrjoTuIdZi76kPIsuy24h9QW8H/oNYxlcR20p7x2lq/Q9V2k4uTstfRjwDaKjTPkJs7tod+BGxjG4i9l+82M80a4idhqcQa5HXAn9D7HDuHWcT8eyn/YhlcTtx291A3IZI6/Z0YAFwHbFp55+JZfj4AGH/NTER3Utcn8uJHbrN+gzxbLfriW3cxxK37cFcSaxBP0bcXmYANxAPqr5CLP+3ENd/S2VZdi+xP+qNxGuTFhPjXw+82sR8FhDPhrqceLD158QzxGDb+vk5sYy+SKxl/VNLvkQdG3z/liqwePXlOVmWzRxsXBm5LF57sBQ4PcuyHxQcjjQwsyuAS7Ms22fQkVtktPcJiFSamZ1DPEp/klhb+yTxCP6uIuMSMLMxxBrwD4kd63OBvyV2budGSUBkdNuH2MTwGuLZTz8Bzmo4dVGKkRHP7rsMmEhM1NcQz7zKjZqDREQqrAodwyIi0o+R2BykqouIyM7Z4eLPkZgEWLFi52/P39XVxZo15bqDchljAsXVLMXVHMXVnF2Na9q0vi/jUHOQiEiFKQmIiFSYkoCISIUpCYiIVJiSgIhIhY3Is4NERKqitnE9LF7ERmrUaIMj59DWObFl81dNQESkpGob15MtXEC28hmyjevj68IFMTG0iJKAiEhZLV4E7W1YW3x+jrW1Q3tbHN4iuTUHhRCWEu+33QN0u/ucEMJVxIdh994//oPu3uonPomIjEwb121NAL2srR02rmvZIvLuE5jr7o2XvF3v7tf2ObaISJV1TiLbsH0iyGo9WOekli1CzUEiImV15BzoqZHV4kP1sloP9NTi8BbJ7VbSIYQnic/rzYAb3P3G1Bx0AbCO+GjCy9x9bR/Tzic+ohB3f9OWLVsaRxmyjo4Ouru7d3r64VDGmEBxNUtxNUdxDU3PhnVsWfRvsHE9dE5k7Jy30r578zWBsWPHQh83kMszCUxz9xUhhH2BfwEuIT4fdA0xMVwNTHX3CweZVaYbyOVDcTVHcTVHcTWnRTeQ2yEJ5NYc5O4r0usq4A7gaHdf6e497l4jPlj76LziERGRnJJACKEzhDCx9z3wNuDhEMLUutHOAB7OIx4REYnyOjtoP+COEELvMr/u7gtDCLeFEGYTm4OWAu/JKR4RESGnJODuTwCz+hh+bh7LFxGRvukUURGRClMSEBGpMCUBEZEKUxIQEakwJQERkQpTEhARqTAlARGRClMSEBGpMCUBEZEKUxIQEakwJQERkQpTEhARqTAlARGRClMSEBGpMCUBEZEKUxIQEakwJQERkQpTEhARqTAlARGRClMSEBGpMCUBEZEKUxIQEakwJQERkQpTEhARqTAlARGRClMSEBGpMCUBEZEKUxIQEakwJQERkQpTEhARqTAlARGRClMSEBGpMCUBEZEK68hrQSGEpcB6oAfodvc5IYS9gW8BBwBLgeDua/OKSUSk6vKuCcx199nuPid9vhy4290PAe5On0VEJCdFNwe9A7g1vb8VeGeBsYiIVI5lWZbLgkIITwJrgQy4wd1vDCG86O571o2z1t336mPa+cB8AHd/05YtW3Y6jo6ODrq7u3d6+uFQxphAcTVLcTVHcTVnV+MaO3YsgO0w312IqVnHufuKEMK+wL+EEB4d6oTufiNwY/qYrVmzZqeD6OrqYlemHw5ljAkUV7MUV3MUV3N2Na5p06b1OTy35iB3X5FeVwF3AEcDK0MIUwHS66q84hERkZySQAihM4Qwsfc98DbgYeD7wPlptPOB7+URj4iIRHnVBPYDfhxC+DXwH8A/u/tC4OPAKSGE3wOnpM8iIpKTXPoE3P0JYFYfw58HTsojBhER2VHRp4iKiEiBlARERCpMSUBEpMKUBEREKkxJQESkwpQEREQqTElARKTClARERCpMSUBEpMKUBEREKkxJQESkwpQEREQqTElARKTClARERCpMSUBEpMKUBEREKkxJQESkwpQEREQqTElARKTClARERCpMSUBEpMKUBEREKkxJQESkwpQEREQqTElARKTClARERCpMSUBEpMKUBEREKkxJQESkwpQEREQqTElARKTClARERCpMSUBEpMI68lxYCKEdWAQsd/fTQghXARcBq9MoH3T3H+YZk4hIleWaBIBLgUeASXXDrnf3a3OOQ0REyLE5KIQwHXg7cHNeyxQRkYHlWRP4NPB+YGLD8PeGEM4jNhNd5u5rc4xJRKTSckkCIYTTgFXu/lAI4YS6f30BuBrI0uungAv7mH4+MB/A3enq6trpWDo6OnZp+uFQxphAcTVLcTVHcTVnuOKyLMtaPtNGIYR/BM4FuoFxxD6BBe5+Tt04BwB3uvsRg8wuW7FixU7H0tXVxZo1a3Z6+uFQxphAcTVLcTVHcTVnV+OaNm0agDUOz6VPwN0/4O7T3f0A4GzgHnc/J4QwtW60M4CH84hHRESivM8OavTJEMJsYnPQUuA9xYYjIlItuScBd78PuC+9Pzfv5YuIyDYDJoEQwjLiUfqA3H1GyyISEZHcDFYTOGeQ/4uIyAg2YBJw9/vzCkRERPI3WHPQh9z9Y+n9R/sbz92vaHVgIiIy/AZrDppe9/61wxmIiIjkb7DmoP9Z9/5dwx+OiIjkqelTREMIE4Eu6q48c/cnWhmUiIjkY8hJIIRwOPA1YBbxtFFj2+mj7a0PTUREhlszt434PHAvsDewDtgLuAE4fxjiEhGRHDSTBGYBf+fuLwLm7i8Bf0u8+6eIiIxAzSSBl4Ex6f2aEMKMNP0+LY9KRERy0UwSeBAI6f13gP8H3A/c3eqgREQkH82cHfQf7n5Lev9B4m2fJxL7BkREZARqJglcAVwL4O414HaAEMILwDWtD01ERIbboEkghHBi77ghhLls/2Sag4D1wxGYiIgMv6HUBL6UXncDvlw3PANWApe0OigREcnHoEnA3Q8ECCF81d3PG/6QREQkL0M+O0gJQERk9MnlQfMiIlJOSgIiIhWmJCAiUmFKAiIiFaYkICJSYUoCIiIVpiQgIlJhSgIiIhWmJCAiUmFKAiIiFaYkICJSYUoCIiIVpiQgIlJhSgIiIhWmJCAiUmFKAiIiFdbMg+Z3WQihHVgELHf300IIewPfAg4AlgLB3dfmGZOISJXlXRO4FHik7vPlwN3ufghwd/osIiI5yS0JhBCmA28Hbq4b/A7g1vT+VuCdecUjIiL5Ngd9Gng/MLFu2H7u/iyAuz8bQti3rwlDCPOB+Wk8urq6djqIjo6OXZp+OJQxJlBczVJczVFczRmuuHJJAiGE04BV7v5QCOGEZqd39xuBG9PHbM2aNTsdS1dXF7sy/XAoW0w9q5+FhQsY+8pmtuw2HuadSfvkqUWHtVXZyquX4mqO4mrOrsY1bdq0Pofn1Rx0HHB6CGEp8E3gxBDC7cDKEMJUgPS6Kqd4pB89q5+Fm66DFU+TbVgHK56Gm66Lw0Vk1MklCbj7B9x9ursfAJwN3OPu5wDfB85Po50PfC+PeGQACxdAexu0pU2jrS1+Xrig2LhEZFgUfZ3Ax4FTQgi/B05Jn6VI617clgB6tbXF4SIy6uR6nQCAu98H3JfePw+clHcMMoBJe8KGddsnglotDi9YbeN6WLyIjdSo0QZHzqGtc+LgE1aUymt0GO71WHRNQMpm3pnQU4s//BBfe2pxeIFqG9eTLVxAtvIZso3r4+vCBXEHkR2ovEaHPNajkoBsp33yVLjofTBtBrb7JJg2Ay56X/FnBy1eBO1tWFs7QHxtb4vDZUcqr9Ehh/WYe3OQlF/75Klw7sXsVaZT5Tau27oj9LK2dti4rqCASk7lNTrksB5VE5CRoXMSWa1nu0FZrQc6JxUUUMmpvEaHHNajkoCMDEfOgZ7a1h0iq/XEvooj5xQcWEmpvEaHHNajmoNkRGjrnEht3pmweBFGDevcQ2e7DEDlNTrksR6VBGTEaOucCMfOpbOri81l6asoMZXX6DDc61HNQSIiFaaagIwYuvipOSovGQrVBGRE0MVPzVF5yVApCcjIoIufmqPykiFSEpCRQRc/NUflJUOkPgEZGTonkW3Y/octq/Vguvipb52TyF5YDatXsYWMDIPJ+2JF3/5DSkc1ARkZdPFTU7KZh8GSx2DDS/DqK/F1yWNxuEgd1QRkRNDFT82xJY+SzXw9rH4OyGDMOJg8BVvyKKg2IHWUBGTE0MVPTdi4Dhs3Dl57AGMnTKB706atw0XqKQnIDnofNL/2lc30lPBB8zIEnZPIXngeVj9X1ycwRX0CsgP1Cch29KD50SH2CTzS0CfwiPoEZAdKArI9PWh+VLAlj8LMQ2H3PWDMbvF15qFxuEgdNQfJ9vSg+dFh4zps3AT1CcigVBOQ7U3ac9vzhXuV5EHz0gQ9VEaGqDI1gTLeTKuMMTHvzNgn0KskD5ovs1KuxyPnwA+WkK1eyZY2I6tlMHk/XVchO6hETaCMN9MqY0xQ4gfNl1RZ1yMAWQaWxfeWxc8iDapRE+jjZlpZ7/Bj5yqmBqV80HxZlXU9Ll4E48djMw7e2ieQ1XqKj0tKpxI1gVLeTKuMMUnzyroeyxqXlE41agJlvPlY5ySyZ56CR3/NxldfhTFj4LBZpbiYp6wXi5Wy7b2sF2WVcZtPSrkeSxzXcKtGTaCENx/L9toHfv4grF8P3a/G158/GIcXqKwXi5W17b20F2WVcJuH8q7HssaVh0okgbbOidi8M7H9pmOdE+PrvDOLzfJ3fhPGjYcxHWAWX8eNj8OLVNaLxUr6kJSyXpRVym0eSrseSxtXDqrRHEQJbz62fh10jIGOMbS1t1HrqW0bXqSyXixW1jbuEl+UVbptHsq9HssYVw4qkwRK1943cRJs2rj9D26tFocXadKe8PwqeOlFXq31QFs77LEnTJlebFxlfUhKWfsEyqrM67GkfSjDrRLNQaVs7zvrwnjedu/VubVa/HzWhcXFBPDmP4KVK+DlzVDria8rV8ThBSrrQ1JK2ydQUmVdj2XtQ8lDJZJAGdv72vefCZd8GPabCuM74+slH47Di/TzB+NR/7jxsRYwbnz8/PMHCw0rtr2/vqHt/fWFt72XtU+grMq6Hkvbh5KDajQHlbS9r33/mfA319BVpouy1r0I48bBlGmMGTOGV199ddvwIpX1ISkl7hMopbKuR0rah5KDXJJACGEc8ACwW1rmd9z9yhDCVcBFwOo06gfd/YctD6Ck7X09Ty2Bb3+Z1Zs3URs/Ac66sPiawKQ94aUXYNMmtt5+bMKE4m8gV9J1WNo27rJSH0rp5NUc9ApworvPAmYD80IIx6T/Xe/us9Nf6xMAlLK9r+epJfDZf4CVz8LmjfH1s/8Qhxfp+D+GF56HV16GWnd8feH5OLxIJVyHUOI27pJSH0r55FITcPcM2JA+jkl/ud3NqpQPKf/2l+P1AfXn49dqcfjfXFNYWLZiGdnsY+DJx+JFbON3hwMPxVYsgwJrKaVch+iB7s2K5XUorF7FtvLaV+VVoNz6BEII7cBDwEzgc+7+sxDCqcB7QwjnAYuAy9x9bR/TzgfmA7g7XV1dzQfQ1QX7H0hHRwed3d278E1aY/XmTfECMQCMtvZ0UdbmTTv3/VpkIzWyKVNgyhTa2tqopbOXjBqdBcYFlG4dQiqvvfeGvfemra2NsWUqr6Sjo6PQbapeLK8u2LtL5dWk4YortyTg7j3A7BDCnsAdIYQjgC8AVxNrBVcDnwJ2OEfS3W8Ebkwfs13pRC1LJ2xt/ARY9xK0tW27WKxWg70nFBpfjTayDeuxtnYmTJjApnT3SevcozSdZWVZh6DyapbKa+ftalzTpk3rc3jup4i6+4vAfcA8d1/p7j3uXgNuAo7OO57ClPU6gZK2vUO8r1HPbZ9j7ccvp+e2zxV+PyOg1OVVSiqv0sklCYQQJqcaACGE8cDJwKMhhPpGwDOAh/OIpwzKep1AWc+XLuuN7cpaXmWl8iqfvJqDpgK3pn6BNsDd/c4Qwm0hhNnE5qClwHtyiqcUSnmdACU9X7qvG9v1Dj/34uLioqTlVWIqr3LJ6+ygxcBRfQw/N4/lyyhQ1hvbiYxw1bhimBLeQK6kMZU2rkl7woZ1O95wr+iL2ChpeYkMUSXuHVTGG8iVMaYyx8W8M2MHYn1Hek8tDi9QactLZIgqkQTKeAO5UsZU4rjaJ0+Fi94H02Zgu0+CaTPgovcV/9jLkpaXyFBVozmojDeQK2NMUN64SIng3IvZq0wd6SUuL5GhqEYSKOPNx8p647EyllWZqbxkhKtGc1AJL1Ap7Y3HSlhWpabykhGuEjWBMt58rKw3HitjWZWZyktGukokASjhBSp6uMaoofKSkawazUFl1DlpaxNCr6zWA2pLFpEcKQkURW3JIlIClWkOKhu1JYtIGSgJFEhtySJSNDUHiYhUmJKAiEiFKQmIiFSYkoCISIUpCYiIVJjODipQWR9GUta4RKT1VBMoSFkfRlLWuERkeCgJFKWsDyMpa1wiMiyUBIpS1oeRlDUuERkWSgJFKesN5Moal4gMCyWBopT1BnJljUtEhoXODipIWW8gV9a4RGR4KAkUqKw3kCtrXCLSemoOEhGpMCUBEZEKUxIQEakwJQERkQpTEhARqTDLsqzoGJo14gIWESkJaxwwEmsCtit/IYSHdnUerf4rY0yKS3EprnL9tSiuHYzEJCAiIi2iJCAiUmFVTAI3Fh1AH8oYEyiuZimu5iiu5gxLXCOxY1hERFqkijUBERFJlARERCqsEncRDSF8GTgNWOXuRxQdT68QwmuBrwJTgBpwo7t/ptioIIQwDngA2I24jXzH3a8sNqptQgjtwCJgubufVnQ8ACGEpcB6oAfodvdSPIAhhLAncDNwBPEamwvd/acFx3Qo8K26QQcBV7j7pwsKaasQwl8D7yaW1W+Ad7n7y8VGBSGES4GLiKd53tTKsqpKTeAWYF7RQfShG7jM3V8PHANcHEI4vOCYAF4BTnT3WcBsYF4I4ZiCY6p3KfBI0UH0Ya67zxVrqHwAAATGSURBVC5LAkg+Ayx098OAWZSg3Nz9sVROs4E3AZuAOwoOixDCa4C/BOakg8V24Oxio4IQwhHEBHA0cR2eFkI4pFXzr0QScPcHgBeKjqORuz/r7r9I79cTd9DXFBsVuHvm7hvSxzHprxRnEIQQpgNvJx7dygBCCJOA44EvAbj7Fnd/sdiodnAS8Li7P1V0IEkHMD6E0AFMAFYUHA/A64F/d/dN7t4N3A+c0aqZV6I5aCQIIRwAHAX8rOBQgK1NLg8BM4HPuXsp4gI+DbwfKNujzjLgrhBCBtzg7mU4zfAgYDXwlRDCLOL6vNTdNxYb1nbOBr5RdBAA7r48hHAt8DSwGbjL3e8qOCyAh4GPhRD2Icb1J8Tm0JaoRE2g7EIIuwPfBf7K3dcVHQ+Au/ek6vp04OhUJS1UCKG3X+ehomPpw3Hu/gfAqcRmveOLDoh4kPcHwBfc/ShgI3B5sSFtE0IYC5wOfLvoWABCCHsB7wAOBKYBnSGEc4qNCtz9EeATwL8AC4FfE5uSW0JJoGAhhDHEBPA1d19QdDyNUvPBfZSjT+U44PTUCftN4MQQwu3FhhS5+4r0uorYvn10sREB8AzwTF0t7jvEpFAWpwK/cPeVRQeSnAw86e6r3f1VYAHw1oJjAsDdv+Tuf+DuxxObtn/fqnkrCRQohGDE9tpH3P26ouPpFUKYnM4qIYQwnrhzPFpsVODuH3D36e5+ALEZ4R53L/xILYTQGUKY2PseeBuxCl8od38OWJbOxoHY/v67AkNq9KeUpCkoeRo4JoQwIe2bJ1GCjnSAEMK+6XUGcCYtLLdK9AmEEL4BnAB0hRCeAa509y8VGxUQj2zPBX4TQvhVGvZBd/9hgTEBTAVuTf0CbYC7+50Fx1Rm+wF3hBAg7lNfd/eFxYa01SXA11LTyxPAuwqOB4AQwgTgFOA9RcfSy91/FkL4DvALYnPLLynPLSS+m/oEXgUudve1rZqxbhshIlJhag4SEakwJQERkQpTEhARqTAlARGRClMSEBGpMCUBEZEKUxIQEakwJQERkQqrxBXDIrsqhHA58Z7u+wLLgA+5+x3pqupPAucTHyrzKeCzwBh37w4h7AFcR7zzYw34CvGK9Z4CvobIDpQERIbmceCPgOeAs4DbQwgziXedPJX48J2N7HhHzFuBlcRbcncCdxKTyA35hC0yMN02QmQnpHs9XUl8ytm33P2GNPxk4i1/xwD7EG9Ktqe7b07//1NgvrvPLSRwkQaqCYgMQQjhPOB9wAFp0O5AF/G+88vqRq1/vz8xGTybbi4HsR+ufhyRQikJiAwihLA/cBPx1sI/dfeeVBMw4Fnig3d6vbbu/TLi85q70mMBRUpHzUEigwghHE68vfAsYAlwHjEp/AXxSP+9xGcI9PYJnMy2juHvAUuBvwc2EJ9aNd3d78/5a4j0SaeIigzC3X9HPOvnp8RO3jcCP0n/vgm4C1hMvP/8D4n3ou89++c8YCzxYS5riU/3mppX7CKDUU1ApIVCCKcCX3T3/YuORWQo1CcgsgvS4zfnEmsD+xHPGLqj0KBEmqDmIJFdY8BHiE09vyQ+k/aKQiMSaYKag0REKkw1ARGRClMSEBGpMCUBEZEKUxIQEakwJQERkQr7/w8zLIFcC0j5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "possum_data=pd.read_csv('possum.csv')\n",
    "age = possum_data['age']\n",
    "tail = possum_data['tailL']\n",
    "plt.scatter(age,tail,alpha = 0.5)\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('tail')\n",
    "plt.title('Relationship between the age and tail length')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "06b100d046292dfb627e90ad458353f0",
     "grade": false,
     "grade_id": "cell-0462afd46977b005",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 2:\n",
    "\n",
    "Recall that the linear model, we obtain predictions by computing \n",
    "\n",
    "$$ \\mathbf{\\hat{y}} = \\mathbf{X} \\beta $$\n",
    "\n",
    "Here, $\\mathbf{X}$ is a design matrix, $\\beta$ are coefficients, and $\\mathbf{\\hat{y}}$ are fitted/estimates/predicted values. Define a model-prediction function `yhat = linearModelPredict(beta,X)` that takes a parameter vector `beta` and a matrix `X` of inputs, and produces a vector `yhat` containing the predicted (fitted) values that correspond to each row of the input matrix. Assume that `beta` has $p$ rows and $1$ column, and that `X` has $n$ rows and $p$ columns.\n",
    "\n",
    "Hint: As of Python 3.5, the `@` symbol can be used for matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b65fc40a6bc00a40421f973f144d5180",
     "grade": false,
     "grade_id": "cell-4827ca1f7be48e94",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def linearModelPredict(b,X):\n",
    "    C = np.array(b) @ np.array(X)\n",
    "    print(C)\n",
    "    raise NotImplementedError()\n",
    "    #return yp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "51e02c8b3c8797aa16514462d764055c",
     "grade": false,
     "grade_id": "cell-468347a5b7c4418c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 3:\n",
    "\n",
    "Write a function `linearModelLossRSS` which computes the loss function for an OLS model parameterized by $\\beta$, as well as the gradient of the loss. Define a squared error loss function `(loss, gradient) = linearModelLossRSS(beta,X,y)` that takes a parameter vector `beta`, a matrix `X` of inputs, and a vector `y` of observed values, and produces the sum of squared errors between the observed and predicted (fitted) values, along with the gradient of the loss. Assume that `theta` has $p$ rows and $1$ column, and that `X` has $n$ rows and $p$ column, and that `y` has `n` rows and `1` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3e8da8d9d20d2a362f6633dadeb1c14c",
     "grade": false,
     "grade_id": "cell-a3c4167aaca2733a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def linearModelLossRSS(b,X,y):\n",
    "    # YOUR CODE HERE\n",
    "    predY = simpleRegPredict(b,X)\n",
    "    residuals = y - predY\n",
    "    residual_sum_of_squares = sum(residuals**2)\n",
    "    \n",
    "    gradient = np.zeros(2)\n",
    "    gradient[0]=...\n",
    "    gradient[1]=...\n",
    "    raise NotImplementedError()\n",
    "    return (residual_sum_of_squares, gradient)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cab0fe1084628c892313e0b145ea80a9",
     "grade": false,
     "grade_id": "cell-943a2a2a74fe1d86",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 4: \n",
    "\n",
    "#### Part 1\n",
    "\n",
    "Now that you've implemented a loss function in question 3, it is now time to minimize it to fit the data!\n",
    "\n",
    "Write a function `linearModelFit` to fit a linear model.  The function should take as its first argument an 2d-array `X` which houses the input data with one example per row, as its second argument a 1d-array `y` of outcomes with one example per row, and as its third argument a function `lossfcn` which returns as a tuple the value of the loss, as well as the gradient of the loss.\n",
    "\n",
    "Use this function to estimate the parameters that describe the relationship between a possum's age and its tail length, i.e., $\\widehat{\\mathit{TailLength}} = \\beta_0 + \\beta_1 \\mathit{age}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "665e16ea4f065c06205fd39030e2f477",
     "grade": false,
     "grade_id": "cell-6b7a37fd82744050",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    return (estimated_betas,R2)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "from numpy import array \n",
    "import scipy.optimize as so\n",
    "\n",
    "def linearModelFit(X,y,lossfcn = linearModelLossRSS):\n",
    "    #estimate b to 0\n",
    "    #minimize the lossfcn\n",
    "    b0 = [0]\n",
    "    so.minimize(lossfcn,b0,args=(X,y))\n",
    "    #computer RSS for linear fit\n",
    "    linearModelLossRSS(b,x,y)\n",
    "    R2 = 1 - (linearModelLossRSS(b,x,y)/#TSS)    \n",
    "    return (estimated_betas,R2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bb234d387f0af37438ab0f67e64ebd04",
     "grade": true,
     "grade_id": "cell-82edf839cc3f9f05",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e330c80ad56a44dd047ec5fe6d7ff175",
     "grade": false,
     "grade_id": "cell-2f605e747adce65f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Part 2\n",
    "\n",
    "Using your solution, plot the data points and the fitted line below. Label your plot and your axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b138f9ba0714a5efb619f9d3171c5bc9",
     "grade": true,
     "grade_id": "cell-1af2aaecb6fd331a",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearModelLossRSS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-cbab3560f7d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mRESULT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearModelLossRSS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRESULT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LinearModelLossRSS' is not defined"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as so\n",
    "bstart=[0,0]\n",
    "RESULT=so.minimize(LinearModelLossRSS,bstart,args=(x, y),jac=True)\n",
    "\n",
    "b=RESULT.x       \n",
    "yp=linearModelPredict(b,x)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "\n",
    "regression_line = linearModelFit(tailL,age,lossfcn)\n",
    "for x in xs :\n",
    "    regression_line\n",
    "\n",
    "possum_data=pd.read_csv('possum.csv')\n",
    "age = possum_data['age']\n",
    "tail = possum_data['tailL']\n",
    "plt.scatter(age,tail,alpha = 0.5)\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('tail')\n",
    "plt.title('Relationship between the age and tail length')\n",
    "plt.plot(xs,regression_line)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cf57584a09cfc7aad4c82e78021c069f",
     "grade": false,
     "grade_id": "cell-dd6a59a07b35a35c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Task 2: Least Absolute Deviation Loss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Question 1: \n",
    "\n",
    "In the previous section, we worked with the squared loss.  Now, we'll implement a linear model with least absolute deviation loss.\n",
    "\n",
    "Write a function `linearModelLossLAD` which computes the least absolute deviation loss function for a linear model  parameterized by $\\beta$, as well as the gradient of the loss.  The function should take as its first argument a 1d-array `beta` of coefficients for the linear model, as its second argument a 2d-array `X` of data, and as its third argument a 1d-array `y` of observed outcomes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "24006c069d9c5caab13c7d133be99e63",
     "grade": false,
     "grade_id": "cell-19835bca47364ef3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def linearModelLossLAD(b,X,y):\n",
    "    predY = simpleRegPredict(b,X)\n",
    "    residuals = y - predY\n",
    "    sum_abs_res = sum (abs (residuals))\n",
    "    grad = sum (X * np.sign (residuals))\n",
    "\n",
    "    return (sum_abs_res, grad)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6058ec251c80efaeb6231d5af08bc9db",
     "grade": false,
     "grade_id": "cell-fa6081b9ab7bbe2a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Use `linearModelLossLAD` to fit a linear model with least absolute deviation loss.  Report the coefficients of the model, the R squared, and plot the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "afe8ee92d2eae0cdce7ed27d5469de67",
     "grade": false,
     "grade_id": "cell-e79c9db0f115eaf6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss \n",
    "import scipy.optimize as so\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def LADFit(x,y,lossfcn = linearModelLossLAD):\n",
    "    b0 =[0]\n",
    "    so.minimize(lossfcn, b0, args = (x,y))\n",
    "    linearModelLossLAD(b,x,y)\n",
    "    yp = linearModelPredict(b,x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7cd2df424700cfc0186d49b0e417029f",
     "grade": true,
     "grade_id": "cell-49ff938735dfe56f",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aa763e935b835a035f5be49a530f9c75",
     "grade": false,
     "grade_id": "cell-8589f0d7e9ec15b3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Plot the fit below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c4eb00628615e30f3227f28ffce114c0",
     "grade": true,
     "grade_id": "cell-33c9fc44613172a8",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as so\n",
    "bstart=[0,0]\n",
    "RESULT=so.minimize(LinearModelLossRSS,bstart,args=(x, y),jac=True)\n",
    "\n",
    "b=RESULT.x       \n",
    "yp=linearModelPredict(b,x)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "\n",
    "regression_line = linearModelFit(tailL,age,lossfcn)\n",
    "for x in xs :\n",
    "    regression_line\n",
    "\n",
    "possum_data=pd.read_csv('possum.csv')\n",
    "age = possum_data['age']\n",
    "tail = possum_data['tailL']\n",
    "plt.scatter(age,tail,alpha = 0.5)\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('tail')\n",
    "plt.title('Relationship between the age and tail length')\n",
    "plt.plot(xs,regression_line)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d272733a3c47bfc9acc8ac6be130df5d",
     "grade": false,
     "grade_id": "cell-72968fb871b8039c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Task 3: Comparing With `Statsmodels`\n",
    "\n",
    "\n",
    "Fit both an OLS and a LAD model with `statsmodels`. Compare coefficient estimates, R squared values, and plot the fits. Discuss any differences or similarities between your implementation and `statsmodels`, and discuss any differences between the OLS model and the LAD model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0eb15994c4e0b0adc78a4f90af5cad85",
     "grade": true,
     "grade_id": "cell-0c3764596ae0cbb9",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    age   R-squared:                       0.223\n",
      "Model:                            OLS   Adj. R-squared:                  0.205\n",
      "Method:                 Least Squares   F-statistic:                     12.62\n",
      "Date:                Mon, 16 Sep 2019   Prob (F-statistic):           0.000925\n",
      "Time:                        15:36:29   Log-Likelihood:                -92.800\n",
      "No. Observations:                  46   AIC:                             189.6\n",
      "Df Residuals:                      44   BIC:                             193.3\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -6.7865      3.037     -2.235      0.031     -12.907      -0.666\n",
      "tailL          0.2957      0.083      3.552      0.001       0.128       0.463\n",
      "==============================================================================\n",
      "Omnibus:                        3.466   Durbin-Watson:                   1.676\n",
      "Prob(Omnibus):                  0.177   Jarque-Bera (JB):                3.296\n",
      "Skew:                           0.623   Prob(JB):                        0.192\n",
      "Kurtosis:                       2.593   Cond. No.                         404.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'regression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d9999f18b1b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mfigure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmgraphics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressionplots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'regression' is not defined"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf \n",
    "import statsmodels.graphics as smgraphics\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "possum_data=pd.read_csv('possum.csv')\n",
    "results = smf.ols('age~tailL', data = possum_data).fit()\n",
    "print(results.summary())\n",
    "\n",
    "figure = smgraphics.regressionplots.plot_fit(regression,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7e629999a11a89294dfb98e910fca049",
     "grade": false,
     "grade_id": "cell-b53337df54c544f0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Discuss differences below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "82444d7e75df67ce5871818bd0c8c991",
     "grade": true,
     "grade_id": "cell-57ea3123d7a6df1d",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-e924d2167a48>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-e924d2167a48>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    I Can tell the much of the difference between the statsmodel that we use and I worked on for the assignments because I could not finish it.\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#There should be almost no difference between the statsmodels and the one with I predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
